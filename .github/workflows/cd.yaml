name: CD

on:
  workflow_call:
    inputs:
      version:
        required: false
        type: string
      environment:
        type: string
        description: environment to deploy to
        required: true

jobs:
  deploy_aws:
    name: Deploy AWS CDK Typescript Stack
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    steps:
      - name: Initiated By User
        run: echo $GITHUB_ACTOR

      - name: Check Out Code
        uses: actions/checkout@v3.1.0

      - name: Install Node
        uses: actions/setup-node@v3.5.0

      - name: Install Dependencies
        working-directory: ./cdk-aws 
        run: npm ci

      - name: Build CDK Stack
        working-directory: ./cdk-aws
        run: npm run build
           
      - name: Bootstrap
        working-directory: ./cdk-aws
        run: "npx cdk bootstrap"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

      - name: Deploy AWS CDK Stack
        working-directory: ./cdk-aws
        run: "npx cdk deploy MyFirstCdkStack --ci --require-approval never --no-asset-metadata"
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_DEFAULT_REGION: ${{ secrets.AWS_DEFAULT_REGION }}

  deploy_databricks:
    #Deploy Databricks CDKTF Stack
    name: Deploy Databricks CDKTF Stack
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    steps:
      - name: check env
        run: echo ${{ inputs.environment }} 
      
      - name: Initiated By User
        run: echo $GITHUB_ACTOR

      - name: Check Out Code
        uses: actions/checkout@v3.1.0

      - name: Install Terraform
        run: |
          wget -O- https://apt.releases.hashicorp.com/gpg | sudo gpg --dearmor -o /usr/share/keyrings/hashicorp-archive-keyring.gpg
          echo "deb [signed-by=/usr/share/keyrings/hashicorp-archive-keyring.gpg] https://apt.releases.hashicorp.com $(lsb_release -cs) main" | sudo tee /etc/apt/sources.list.d/hashicorp.list
          sudo apt update && sudo apt install terraform
          terraform -v

      - name: Install nvm
        run: |
          cat ~/.bashrc
          curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.5/install.sh | bash
          export NVM_DIR="$HOME/.nvm"
          [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"  # This loads nvm
          [ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"  # This loads nvm bash_completion
          source ~/.bashrc
          command -v nvm
          nvm install 16
          node -v
          npm -v
          
      - name: Install dependencies
        working-directory: ./cdk-tf
        run: |
          npm install

      - name: Install cdktf cli
        run: |
          npm install -g cdktf-cli
          cdktf --version

      - name: Install typescript
        run: |
          npm install -g typescript
          tsc -v

      - name: Install databricks cli
        run: |
          curl -fsSL https://raw.githubusercontent.com/databricks/setup-cli/main/install.sh | sh
          databricks -v

      - name: cdk-databricks
        run: |
          npm install @cdktf/provider-databricks --force
          npm install --save-dev @types/node

      - name: deploy resources
        working-directory: ./cdk-tf   
        run: |
          sudo cdktf synth
          sudo cdktf deploy --auto-approve --var='host=${{ secrets.DATABRICKS_HOST }}' --var='token=${{ secrets.DATABRICKS_TOKEN }}'
        
  airflow_dag:
    #DAG to s3
    name: DAG to s3
    runs-on: ubuntu-latest
    environment: ${{ inputs.environment }}
    steps:
      - name: check env
        run: echo ${{ inputs.environment }} 
      
      - name: Initiated By User
        run: echo $GITHUB_ACTOR

      - name: Check Out Code
        uses: actions/checkout@v3.1.0

      - uses: jakejarvis/s3-sync-action@master
        with:
          args: --follow-symlinks
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          AWS_S3_BUCKET: ${{ secrets.MWAA_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_DEFAULT_REGION }}
          SOURCE_DIR: dag/${{ inputs.environment }}
          DEST_DIR: 'sample'
          